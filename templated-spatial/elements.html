<!DOCTYPE HTML>
<!--
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>Project Description</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body>

		<!-- Header -->
			<header id="header">
			
				<nav id="nav">
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="generic.html">Member Description</a></li>
						<li><a href="elements.html">Project Description</a></li>
					</ul>
				</nav>
			</header>

			<a href="#menu" class="navPanelToggle"><span class="fa fa-bars"></span></a>

		<!-- Main -->
			<section id="main" class="wrapper">
				<div class="container">
					<header class="major special">
						<h2>Project Description</h2>
						<p>AKCSE </p>
					</header>

					<!-- Text -->
						<h1> Web Development Team</h1>
						<p> As a front end team we worked on the main website development. 
							The website includes the project description, member description along with project simulator page. Using HTML and CSS, we constructed the main structure of the web page. 
							For web design we used Javascript. Furthermore, we used Python to receive image input & transfer the received image to the Python program. 
							We then displayed the output image/text from the Python to the website and ran the Python program using HTML(website).</p>

						<h1> Data Scraping</h1>
						<p> Data Scaping Team: Dataset: where you got those data, etc
							Data Scraping:
							3D to 2D Conversion: 
							Data Augmentation:
							Image Classification Using CNN:
							
							We created a data scraping code to automatically download large samples of sagittal MRI images from Google. 
							We further filtered out the downloaded files using image classification to find the best test samples. 
							3D Medical images in MHA and DICOM format were also analyzed and collected to broaden our sample size for machine learning. 
							Slicer was used to view 3D DICOM images and MATLAB was used to convert 3D MHA images into 2D binary images for processing.</p>

						<h1> Image Segmentation</h1>
						<p> Image segmentation team: Mask layer generation:
							U-Net Model:
							The U-Net architecture was inspired by U-Net: Convolutional Networks for Biomedical Image Segmentation. 
							Between each layer, the size of the layer is reduced to avoid overflow. It is implemented with Keras functional API.</p>
<img src="/Image segmentation pic.png" height= "500px" width="700px" >

<h1> Image Augmentation</h1>
<p>Image Augmentation
	Purpose: For massive increase in the scale of datasets that will be used for training/validation/test process during image classification.</p>
	<img src="/Augmentation.png" height="500px" width="700px">

	<p>→ It is necessary to create transformed versions of original images, such as by applying image flip/rotation, changing image contrast, etc.

		Tools: Augmenting data using PyTorch (open source machine learning library)
		→ Torchvision.transforms modules are used for image transformation.
		Link: https://pytorch.org/
		
		Procedure:
		Load Data
		→ Suppose that datasets are given (from (2) and (3)) with original brain images and its corresponding masked images. Datasets must be already splitted into training/validation/test set and the only training set (and possibly validation set) will be used for data augmentation.
		Create a new class that takes a Dataset argument where the Dataset refers to PyTorch’s Dataset from torch.utils.data module.
		→ The class should include function transform where data augmentation occurs
		Prepare a three (or more) datasets:
		Original datasets (original brain images and its masked images)
		Augmented datasets 1
		Augmented datasets 2
		… (As many augmented datasets as desired)
		Initialize each dataset by passing self, the parameter for image paths, and the parameter for masked(segmented) image path from training set, into the class.
		During the transformation (from the transform function within the class):
		Images (both original brain image and its masked image) are resized
		Images are randomly flipped (vertically and horizontally), and randomly rotated. 
		(!!! Brain images and its corresponding masked images are transformed/augmented in a same fashion)
		 Images are converted into tensor form, and normalized
		The class returns both transformed brain images and its masked images
		Create three (or more) DataLoader objects and insert each transformed datasets (from 3) as an argument for the object.
		→ DataLoader class is designed to iterate all the values in the dataset and returns its tuples, instead of using for-loops to iterate over the dataset.
		Save images as a png format from DataLoaders into directory
		→ Make a large folder for storing augmented results. Create subfolders for every different brain image. Inside each subfolders, store:
		Original brain image
		Original brain masked image
		Augmented(1) brain image
		Augmented(1) brain masked image
		Augmented(2) brain image
		Augmented(2) brain masked image</p>
		<!-- Footer -->
			<footer id="footer">
				
					<ul class="copyright">
						<li>&copy; Untitled</li>
						<li>Design: <a href="http://templated.co">TEMPLATED</a></li>
						<li>Images: <a href="http://unsplash.com">Unsplash</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>